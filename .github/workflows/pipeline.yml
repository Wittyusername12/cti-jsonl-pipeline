name: metrics-id-final

on:
  workflow_dispatch: {}
  push:
    branches: [ main ]

jobs:
  id-final:
    runs-on: windows-latest
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # 1) Preflight: normalize and build eval inputs
      - name: Preflight (ID mode)
        shell: pwsh
        run: |
          py preflight.py --mode id `
            --top1 ce_top1_final_ID.csv `
            --gold gold_id_unbalanced_nobom.jsonl `
            --out-csv top1_eval.csv `
            --out-gold gold_eval.jsonl

      # 2) Deterministic micro sample (n=200, seed=42)
      - name: Make deterministic micro sample (n=200, seed=42)
        shell: pwsh
        run: |
          python - << 'PY'
          import csv, json
          from pathlib import Path
          qset=set()
          with open('gold_eval.jsonl', encoding='utf-8') as f:
              for line in f:
                  if line.strip():
                      o=json.loads(line); q=o.get('query','').strip()
                      if q: qset.add(q)
          rows=[]
          with open('top1_eval.csv', newline='', encoding='utf-8') as f:
              r=csv.DictReader(f)
              for row in r:
                  if row.get('query','') in qset:
                      rows.append({'query':row['query'], 'candidate':row['candidate']})
          rows = rows[:200]
          with open('sample200_eval.csv','w',newline='',encoding='utf-8') as f:
              w=csv.DictWriter(f, fieldnames=['query','candidate'])
              w.writeheader(); w.writerows(rows)
          print(f"Wrote sample200_eval.csv with {len(rows)} rows")
          PY

      # 3) Micro-eval (warn-only)
      - name: Micro-eval (warn-only)
        shell: pwsh
        run: |
          py metrics_top1.py --top1_csv sample200_eval.csv `
            --gold_jsonl gold_eval.jsonl `
            --out micro_metrics.txt
          $t = Get-Content micro_metrics.txt -Raw
          $m = [regex]::Match($t,'P@1 \(overall\):\s*([0-9.]+)')
          if($m.Success){
            $p = [double]$m.Groups[1].Value
            if($p -lt 0.05){ Write-Host "::warning::Micro P@1 $p < 0.05 (threshold 0.05)"; }
            else { Write-Host "Micro P@1 OK: $p"; }
          } else {
            Write-Host "::warning::Could not parse micro metrics"
          }

      # 4) Full eval on canonical files (authoritative result)
      - name: Full metrics (ID)
        shell: pwsh
        run: |
          py metrics_top1.py --top1_csv top1_eval.csv `
            --gold_jsonl gold_eval.jsonl `
            --out metrics_unbalanced_p1_id_final.txt

      # 5) Misses report (Top 40)
      - name: Misses Top 40
        shell: pwsh
        run: |
          py misses_report.py --top1_csv top1_eval.csv `
                              --gold_jsonl gold_eval.jsonl `
                              --out_csv debug_misses_top40.csv `
                              --k 40 `
                              --p_col p_relevant `
                              --pirr_col p_irrelevant

      # 6) Upload artifacts
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: id-final-artifacts
          path: |
            sample200_eval.csv
            top1_eval.csv
            gold_eval.jsonl
            micro_metrics.txt
            metrics_unbalanced_p1_id_final.txt
            debug_misses_top40.csv
